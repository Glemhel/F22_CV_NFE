{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Generation\n",
        "Generate 10 000 anime faces with our GAN."
      ],
      "metadata": {
        "id": "93eRXuCJc5Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "from scipy import linalg"
      ],
      "metadata": {
        "id": "ReCx5aBnPwzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualLR:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def compute_weight(self, module):\n",
        "        weight = getattr(module, self.name + '_orig')\n",
        "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
        "\n",
        "        return weight * math.sqrt(2 / fan_in)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(module, name):\n",
        "        fn = EqualLR(name)\n",
        "\n",
        "        weight = getattr(module, name)\n",
        "        del module._parameters[name]\n",
        "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
        "        module.register_forward_pre_hook(fn)\n",
        "\n",
        "        return fn\n",
        "\n",
        "    def __call__(self, module, input):\n",
        "        weight = self.compute_weight(module)\n",
        "        setattr(module, self.name, weight)\n",
        "\n",
        "\n",
        "def equal_lr(module, name='weight'):\n",
        "    EqualLR.apply(module, name)\n",
        "\n",
        "    return module"
      ],
      "metadata": {
        "id": "rG9jS-VvaSOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualLinear(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        linear = nn.Linear(in_dim, out_dim)\n",
        "        linear.weight.data.normal_()\n",
        "        linear.bias.data.zero_()\n",
        "\n",
        "        self.linear = equal_lr(linear)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "KSMaXsrsaQ53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        conv = nn.Conv2d(*args, **kwargs)\n",
        "        conv.weight.data.normal_()\n",
        "        conv.bias.data.zero_()\n",
        "        self.conv = equal_lr(conv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)"
      ],
      "metadata": {
        "id": "H90OUq7QaRdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConstantInput(nn.Module):\n",
        "    def __init__(self, channel, size=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input = nn.Parameter(torch.randn(1, channel, size, size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch = x.shape[0]\n",
        "        out = self.input.repeat(batch, 1, 1, 1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "InEq2RH2amvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoiseInjection(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
        "\n",
        "    def forward(self, image, noise):\n",
        "        return image + self.weight * noise"
      ],
      "metadata": {
        "id": "QgG6rFIVamo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveInstanceNorm(nn.Module):\n",
        "    def __init__(self, in_channel, style_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.InstanceNorm2d(in_channel)\n",
        "        self.style = nn.Linear(style_dim, in_channel * 2)\n",
        "        self.style.bias.data[:in_channel] = 1\n",
        "        self.style.bias.data[in_channel:] = 0\n",
        "\n",
        "    def forward(self, input, style):\n",
        "        style = self.style(style).unsqueeze(2).unsqueeze(3)\n",
        "        gamma, beta = style.chunk(2, 1)\n",
        "\n",
        "        out = self.norm(input)\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "aMrrx-tnameR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlurFunctionBackward(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, grad_output, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            grad_output, kernel_flip, padding=1, groups=grad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, gradgrad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            gradgrad_output, kernel, padding=1, groups=gradgrad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "class BlurFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        output = F.conv2d(input, kernel, padding=1, groups=input.shape[1])\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = BlurFunctionBackward.apply(grad_output, kernel, kernel_flip)\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "blur = BlurFunction.apply\n",
        "\n",
        "\n",
        "class Blur(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        weight = torch.tensor([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=torch.float32)\n",
        "        weight = weight.view(1, 1, 3, 3)\n",
        "        weight = weight / weight.sum()\n",
        "        weight_flip = torch.flip(weight, [2, 3])\n",
        "\n",
        "        self.register_buffer('weight', weight.repeat(channel, 1, 1, 1))\n",
        "        self.register_buffer('weight_flip', weight_flip.repeat(channel, 1, 1, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return blur(input, self.weight, self.weight_flip)"
      ],
      "metadata": {
        "id": "z9O_rfpaas91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyledConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size=3,\n",
        "        padding=1,\n",
        "        style_dim=512,\n",
        "        initial=False,\n",
        "        upsample=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if initial:\n",
        "            self.conv1 = ConstantInput(in_channel)\n",
        "\n",
        "        else:\n",
        "            if upsample:\n",
        "                self.conv1 = nn.Sequential(\n",
        "                    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                    EqualConv2d(\n",
        "                        in_channel, out_channel, kernel_size, padding=padding\n",
        "                    ),\n",
        "                    Blur(out_channel),\n",
        "                )\n",
        "            else:\n",
        "                self.conv1 = EqualConv2d(\n",
        "                    in_channel, out_channel, kernel_size, padding=padding\n",
        "                )\n",
        "\n",
        "        self.noise1 = NoiseInjection(out_channel)\n",
        "        self.adain1 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.conv2 = EqualConv2d(out_channel, out_channel, kernel_size, padding=padding)\n",
        "        self.noise2 = NoiseInjection(out_channel)\n",
        "        self.adain2 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x, style, noise):\n",
        "        out = self.conv1(x)\n",
        "        out = self.noise1(out, noise)\n",
        "        out = self.lrelu1(out)\n",
        "        out = self.adain1(out, style)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.noise2(out, noise)\n",
        "        out = self.lrelu2(out)\n",
        "        out = self.adain2(out, style)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "XIbO8ZhIah05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=512, n_linear=5):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(n_linear):\n",
        "            layers.append(EqualLinear(z_dim, z_dim))\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        self.style = nn.Sequential(*layers)\n",
        "        self.progression = nn.ModuleList(\n",
        "            [\n",
        "              StyledConvBlock(512, 512, 3, 1, initial=True),\n",
        "              StyledConvBlock(512, 512, 3, 1, upsample=True),\n",
        "              StyledConvBlock(512, 256, 3, 1, upsample=True),\n",
        "              StyledConvBlock(256, 128, 3, 1, upsample=True),\n",
        "              StyledConvBlock(128, 64, 3, 1, upsample=True),\n",
        "            ]\n",
        "        )\n",
        "        self.to_rgb = EqualConv2d(64, 3, 1)\n",
        "\n",
        "    def forward(self, x, noise=None, step=0):\n",
        "        batch = x.size(0)\n",
        "        if noise is None:\n",
        "            noise = []\n",
        "            for i in range(step + 1):\n",
        "                size = 4 * 2 ** i\n",
        "                noise.append(torch.randn(batch, 1, size, size, device=x[0].device))\n",
        "        x = x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)\n",
        "        styles = self.style(x)\n",
        "        out = noise[0]\n",
        "        for i, conv in enumerate(self.progression):\n",
        "            out = self.progression[i](out, styles, noise[i])\n",
        "        return self.to_rgb(out)"
      ],
      "metadata": {
        "id": "w8CHA_vzaDsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDOIOPfwKbpe"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "G = torch.load('Generator_v2_150.pth', map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_random_image(G, index):\n",
        "    img_size = 64\n",
        "    step = int(math.log(img_size, 2)) - 2\n",
        "    z = torch.randn((1, 512))\n",
        "    with torch.no_grad():\n",
        "        img = G(z, step=step)[0]\n",
        "    imgpath = f'generated_images/random_image_{index}.png'\n",
        "    imgdata = torch.clip(img, 0, 1).permute([1, 2, 0]).detach().cpu().numpy()\n",
        "    plt.imsave(imgpath, imgdata)\n",
        "    return imgpath, z"
      ],
      "metadata": {
        "id": "tQGTJLzUKpJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10000):\n",
        "    generate_and_save_random_image(G, i)"
      ],
      "metadata": {
        "id": "fOTmH8fcbU4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMv9ku1n5d3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}